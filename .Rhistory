geom_path() +
## geom_errorbar()       +
background_grid(major = "xy", minor = "none")+
xlab("Claimed Posterior Probability")+
ylab("Empirical probability of Causality")+theme(legend.position = "none")+
theme(axis.text=element_text(size=10),
axis.title=element_text(size=12))
ggplot(data = data,
mapping = aes(x=pps.new, y=cv.binary, ymin=cv.low,ymax=cv.high),col=2) +
geom_abline(col="grey",linetype="dashed") +
geom_ribbon(alpha=0.1,col="grey") +
geom_path() +
## geom_errorbar()       +
background_grid(major = "xy", minor = "none")+
xlab("Claimed posterior probability")+
ylab("Empirical probability of causality")+theme(legend.position = "none")+
theme(axis.text=element_text(size=10),
axis.title=element_text(size=12))
1e+4
load(url("http://www.stats.gla.ac.uk/~claire/aptslab1.RData"))
ls(divorces)
head(divorces)
ls(engel)
head(engel)
head(gbr)
head(Mammals)
head(radiocarbon)
ls(bbase)
plot(divorces)
fit <- lm(divorce~poly(year,3))
fit <- lm(divorce~poly(year,3), data = divorces)
fit
x <- seq(1920, 2000, 10)
lines(x, predict(fit, x), col = 2)
x <- data.frame("year" = seq(1920, 2000, 10))
lines(x, predict(x, fit), col = 2)
x
lines(x, predict(fit, x), col = 2)
x
predict(fit, x)predict(fit, x)
predict(fit, x)
lines(x, data.frame(predict(fit, x), col = 2)
lines(x, data.frame(predict(fit, x)), col = 2)
lines(x, data.frame(predict(fit, x)), col = 2)
?lines
lines(x, predict(fit), col = 2)
y.new <- predict(fit, x)
cbind(x, y.new)
new <- cbind(x, y,new)
new <- cbind(x, y.new)
lines(x, predict(fit), col = 2)
lines(new$year, new$y.new, col = 2)
fit <- lm(divorce~poly(year,2), data = divorces)
x <- data.frame("year" = seq(1920, 2000, 10))
y.new <- predict(fit, x)
new <- cbind(x, y.new)
lines(new$year, new$y.new, col = 2)
plot(divorces)
fit <- lm(divorce~poly(year,4), data = divorces)
x <- data.frame("year" = seq(1920, 2000, 10))
y.new <- predict(fit, x)
new <- cbind(x, y.new)
lines(new$year, new$y.new, col = 2)
library(splines)
lm(divorce~bs(year, df = 6))
lm(divorce~bs(year, df = 6), data = divorces)
lm(divorce~bs(year, df = 6), data = divorces)
plot(divorces)
x <- data.frame("year" = seq(1920, 2000, 10))
y.new <- predict(fit, x)
new <- cbind(x, y.new)
lines(new$year, new$y.new, col = 2)
lm(divorce~bs(year, df = 7), data = divorces)
plot(divorces)
x <- data.frame("year" = seq(1920, 2000, 10))
y.new <- predict(fit, x)
new <- cbind(x, y.new)
lines(new$year, new$y.new, col = 2)
lm(divorce~bs(year, df = 15), data = divorces)
plot(divorces)
x <- data.frame("year" = seq(1920, 2000, 10))
y.new <- predict(fit, x)
new <- cbind(x, y.new)
lines(new$year, new$y.new, col = 2)
?bs
library(splines)
fit <- lm(divorce~bs(year, df = 15), data = divorces)
plot(divorces)
x <- data.frame("year" = seq(1920, 2000, 10))
y.new <- predict(fit, x)
new <- cbind(x, y.new)
lines(new$year, new$y.new, col = 2)
?bs
?ns
fit <- lm(divorce~ns(year, df = 5), data = divorces)
plot(divorces)
x <- data.frame("year" = seq(1920, 2000, 10))
y.new <- predict(fit, x)
new <- cbind(x, y.new)
lines(new$year, new$y.new, col = 2)
?ns
par(mfrow=c(1,2))
library(splines)
fit <- lm(divorce~bs(year, df = 10), data = divorces)
plot(divorces, main = "B spline (10 dfs)")
x <- data.frame("year" = seq(1920, 2000, 10))
y.new <- predict(fit, x)
new <- cbind(x, y.new)
lines(new$year, new$y.new, col = 2)
####
fit <- lm(divorce~ns(year, df = 10, data = divorces)
plot(divorces, main = "Natural cubic spline (10 dfs)")
x <- data.frame("year" = seq(1920, 2000, 10))
y.new <- predict(fit, x)
new <- cbind(x, y.new)
lines(new$year, new$y.new, col = 2)
fit <- lm(divorce~ns(year, df = 10), data = divorces)
plot(divorces, main = "Natural cubic spline (10 dfs)")
x <- data.frame("year" = seq(1920, 2000, 10))
y.new <- predict(fit, x)
new <- cbind(x, y.new)
lines(new$year, new$y.new, col = 2)
?bs
?tbase
??tbase
View(tbase)
B  <- tbase(longitude, n.knots=4, deg=3)
attach(gbr)
B  <- tbase(longitude, n.knots=4, deg=3)
B
head(gbr)
beta <- solve(crossprod(B), t(B)%*%y)
beta <- solve(crossprod(B), t(B)%*%score1)
beta
yhat <- B%*%beta
yhat
plot(longitude, score1)
lines(score1, yhat, col = 2)
yhat
plot(longitude, score1)
score1
plot(score1, longitude)
lines(score1, yhat, col = 2)
plot(longitude, score1)
lines(longitude, yhat)
library(ggplot2)
library(mgcv)
p <- ggplot(gbr, aes(longitude, score1))
p
p + geom_point(colour = "darkblue") + geom_smooth(method = "gam", formula=y~s(x), colour="red")
pspline.cartoon(radiocarbon)
install.packages("rpanel")
library(rpanel)
install.packages("BWidget")
data(engel)
attach(engel)
View(x)
rm(x)
data(engel)
attach(engel)
head(engel)
attach(engel)
x <-income
y <- foodexp
data(engel)
attach(engel)
x <-income
data(engel)
load(url("http://www.stats.gla.ac.uk/~claire/aptslab1.RData"))
data(engel)
attach(engel)
x <-income
y <- foodexp
head(engel)
x
y
x <- engel$x
y <- engel$y
##(a)
plot(x,y)
##(b)
require(quantreg)
install.packages("quantreg")
library(quantreg)
##(b)
require(quantreg)
plot(x,y,cex=.25,type="n",xlab="Household Income",
ylab="Food Expenditure")
points(x,y,cex=.5,col="blue")
abline(rq(y~x,tau=.5),col="blue")
abline(lm(y~x),lty=2,col="red") #ols line
?rq
##(c)
taus <- c(.05,.1,.25,.75,.90,.95)
f <- rq(y ~ x, tau = taus)
for( i in 1:length(taus)){
abline(coef(f)[,i],col="grey")
}
##(d)
z <- rq(y~x,tau=-1)
z$sol
##(e)
#Poor is defined as at the .1 quantile of the sample distn
x.poor <- quantile(x,.1)
#Rich is defined as at the .9 quantile of the sample distn
x.rich <- quantile(x,.9)
z
ps <- z$sol[1,]
ps
qs.poor <- c(c(1,x.poor)%*%z$sol[4:5,])
qs.rich <- c(c(1,x.rich)%*%z$sol[4:5,])
plot(c(ps,ps),c(qs.poor,qs.rich),type="n",
xlab=expression(tau),ylab="quantile")
plot(stepfun(ps,c(qs.poor[1],qs.poor)),do.points=FALSE,add=TRUE)
plot(stepfun(ps,c(qs.poor[1],qs.rich)),do.points=FALSE,add=TRUE)
##(f)
fit.25 <- rq(y~x,tau=.25)
summary(fit.25)
fit.75 <- rq(y~x,tau=.75)
summary(fit.75)
anova(fit.25,fit.75)
install.packages("FrF2")
library(FrF2)
?F`FrF2-package`
?FrF2
desgin <- FrF2(16, 9, factor.names = paste0("x", 1:9), generators = list(c(1,2,3), c(1,2,4),c(1,3,4), c(2,3,4), c(1,2,3,4)), randomize = F, alias.info = 3)
design <- FrF2(16, 9, factor.names = paste0("x", 1:9), generators = list(c(1,2,3), c(1,2,4),c(1,3,4), c(2,3,4), c(1,2,3,4)), randomize = F, alias.info = 3)
design
design.info(design)$aliased
?fold.design
folded <- fold.design(design, columns = "full")
folded
folded_5 <- fold.design(design, columns = "5")
folded_5 <- fold.design(design, columns = 5)
folded_5
q2a <- FrF2(32, 5, blocks = 4)
q2a
design.info(q2a)$aliased.with.blocks
load(url("https://www.stats.gla.ac.uk/~claire/aptslab2.RData"))
load(url("http://www.stats.gla.ac.uk/~claire/aptslab2.RData"))
attach(CZ03)
##(a)
pairs(CZ03)
##(b)
library(mgcv)
model1 <- gam(SO2 ~ s(Year) + s(Week), data = CZ03)
model1
plot(model1)
plot(model1)
?gam
##(c)
model2 <- gam(SO2 ~ s(Year) + s(Week) + s(Rain) + s(Temp) +
s(Humidity), data = CZ03)
par(mfrow = c(2, 3))
plot(model2)
par(mfrow = c(1, 1))
##(d)
anova(model1)
anova(model2)
anova(model1,model2, test='F')
##(e)
model3 <- gam(SO2 ~ s(Year) + s(Week) + s(Rain) + s(Temp) +
s(Humidity), method='REML', data = CZ03)
model3
par(mfrow = c(2, 3))
plot(model2)
par(mfrow = c(1, 1))
summary(model3)
##(a)
library(gamlss)
install.packages("gamlss")
##(a)
library(gamlss)
data(dbbmi)
plot(bmi~age, data=dbbmi, pch = 15, cex = 0.5, col = gray(0.5))
##(b)
library(mgcv)
m0 <- gam(bmi ~ s(age), data=dbbmi)
lines(dbbmi$age, fitted(m0))
library(quantreg)
?rqss
set.seed(1)                                           # ensure reproducibility
n=10000; n1p=100; n1pq=100; n1q=100                   # parameters
zp=c(rnorm(n1p,sd=3), rnorm(n1q,sd=1),
rnorm(n1pq,sd=3), rnorm(n-n1p-n1q-n1pq,sd=1))    # simulate z-scores corresponding to p
zq=c(rnorm(n1p,sd=1), rnorm(n1q,sd=3),
rnorm(n1pq,sd=3), rnorm(n-n1p-n1q-n1pq,sd=1))    # simulate z-scores corresponding to q
p=2*pnorm(-abs(zp)); q=2*pnorm(-abs(zq))              # conv
fold_id=(1:n) %% 3
fold_id
fold1
set.seed(1)                                           # ensure reproducibility
n=10000; n1p=100; n1pq=100; n1q=100                   # parameters
zp=c(rnorm(n1p,sd=3), rnorm(n1q,sd=1),
rnorm(n1pq,sd=3), rnorm(n-n1p-n1q-n1pq,sd=1))    # simulate z-scores corresponding to p
zq=c(rnorm(n1p,sd=1), rnorm(n1q,sd=3),
rnorm(n1pq,sd=3), rnorm(n-n1p-n1q-n1pq,sd=1))    # simulate z-scores corresponding to q
p=2*pnorm(-abs(zp)); q=2*pnorm(-abs(zq))              # convert to p-values
fold_id=(1:n) %% 3
candidate_indices=which(p<0.01 | q< 0.001)
example_indices=example_indices=c(4262, 268,83,8203)
# True parameters
true_q0_pars=c(1- n1q/(n-n1p-n1pq),2)
# Estimated parameters:
est_q0_pars=fit.2g(q[which(p>0.5)])$pars
true_q0_pars
library(cfdr)
# Estimated parameters:
est_q0_pars=fit.2g(q[which(p>0.5)])$pars
est_q0_pars
lx=vl(p,q,indices=candidate_indices,mode=1);
vx=vl(p,q,indices=example_indices,mode=1);
plot(p,q,cex=0.5,col="gray",xlim=c(0,0.001),ylim=c(0,1), main="Single point removed");
for (i in 1:length(example_indices)) lines(vx$x[i,],vx$y);
for (i in 1:length(example_indices)) points(p[example_indices[i]],q[example_indices [i]],pch=16,col="blue")
set.seed(1)                                           # ensure reproducibility
n=10000; n1p=100; n1pq=100; n1q=100                   # parameters
zp=c(rnorm(n1p,sd=3), rnorm(n1q,sd=1),
rnorm(n1pq,sd=3), rnorm(n-n1p-n1q-n1pq,sd=1))    # simulate z-scores corresponding to p
zq=c(rnorm(n1p,sd=1), rnorm(n1q,sd=3),
rnorm(n1pq,sd=3), rnorm(n-n1p-n1q-n1pq,sd=1))    # simulate z-scores corresponding to q
p=2*pnorm(-abs(zp)); q=2*pnorm(-abs(zq))              # convert to p-values
candidate_indices=which(p<0.01 | q< 0.001)
est_q0_pars=fit.2g(q[which(p>0.5)])$pars
library(cfdr)
est_q0_pars=fit.2g(q[which(p>0.5)])$pars
est_q0_pars
library(cfdr)
set.seed(1)                                           # ensure reproducibility
new_sd <- 5
n=1000; n1p=50; n1pq=50; n1q=50                   # parameters
par(mfrow = c(1,2))
zp=c(rnorm(n1p,sd=new_sd), rnorm(n1q,sd=1),
rnorm(n1pq,sd=new_sd), rnorm(n-n1p-n1q-n1pq,sd=1))    # simulate z-scores corresponding to p
zq=c(rnorm(n1p,sd=1), rnorm(n1q,sd=3),
rnorm(n1pq,sd=3), rnorm(n-n1p-n1q-n1pq,sd=1))    # simulate z-scores corresponding to q
P=2*pnorm(-abs(zp)); Q=2*pnorm(-abs(zq))              # convert to p-values
rough_cfdr=function(p,q) p*length(which(Q <= Q))/length(which(P <= p & Q <= q))
plot(p, rough_cfdr)
plot(P, rough_cfdr)
plot(P, rough_cfdr(P,Q))
identical(P, rough_cfdr(P,Q))
identical(-log10(P), -log10(rough_cfdr(P,Q)))
identical(-log10(P), -log10(rough_cfdr(P,Q)))
plot(-log10(P), -log10(rough_cfdr(P,Q)))
packages <- c(
'ggplot2',
'ggrepel',
'patchwork',
'ggraph',
'dplyr',
'patchwork',
'gganimate',
'gifski',
'ggrepel',
'ggforce',
'ggraph',
'ggthemes',
'maps',
'sf',
'tidyr',
'concaveman',
'remotes'
)
data("faithful")
# Basic scatterplot
ggplot(data = faithful,
mapping = aes(x = eruptions, y = waiting)) +
geom_point()
# Data and mapping can be given both as global (in ggplot()) or per layer
ggplot() +
geom_point(mapping = aes(x = eruptions, y = waiting),
data = faithful)
head(faithful)
ggplot(faithful) +
geom_point(aes(x = eruptions, y = waiting, colour = eruptions < 3))
ggplot(faithful) +
geom_point(aes(x = eruptions, y = waiting),
colour = 'steelblue')
ggplot(faithful) +
geom_histogram(aes(x = eruptions))
ggplot(faithful, aes(x = eruptions, y = waiting)) +
geom_density_2d() +
geom_point()
ggplot(faithful) +
geom_point(aes(x = eruptions, y = waiting), alpha = 0.1, size = 2)
ggplot(faithful) +
geom_point(aes(x = eruptions, y = waiting), alpha = 0.1, size = 5)
ggplot(faithful) +
geom_point(aes(x = eruptions, y = waiting, alpha = 0.1))
ggplot(faithful) +
geom_point(aes(x = eruptions, y = waiting, size = 5))
ggplot(faithful) +
geom_point(aes(x = eruptions, y = waiting), alpha = 0.1, size = 2)
ggplot(faithful) +
geom_histogram(aes(x = eruptions))
ggplot(faithful) +
geom_histogram(aes(x = eruptions, col = eruptions >3))
ggplot(faithful) +
geom_histogram(aes(x = eruptions, fill = eruptions >3))
ggplot(faithful) +
geom_histogram(aes(x = eruptions, fill =
waiting > 60))
ggplot(faithful) +
geom_histogram(aes(x = eruptions, fill =
waiting > 60), position = 'dodge')
ggplot(faithful) +
geom_histogram(aes(x = eruptions, fill =
waiting > 60, position = 'dodge'))
ggplot(faithful) +
geom_histogram(aes(x = eruptions, fill =
waiting > 60), position = 'dodge')
ggplot(faithful) +
geom_histogram(aes(x = eruptions, fill =
waiting > 60), position = "dodge")
?ggplot2::position_dodge
ggplot(faithful) +
geom_histogram(aes(x = eruptions, fill = eruptions >3))
ggplot(faithful) +
geom_histogram(aes(x = eruptions, fill =
waiting > 60), position = "dodge")
ggplot(faithful) +
geom_histogram(aes(x = eruptions, fill =
waiting > 60), position = "dodge2")
ggplot(faithful) +
geom_histogram(aes(x = eruptions, fill =
waiting > 60), position = "dodge2")
data("mpg")
ggplot(mpg) +
geom_bar(aes(x = class))
library(dplyr)
mpg_counted <- mpg %>%
count(class, name = 'count')
ggplot(mpg_counted) +
geom_bar(aes(x = class, y = count), stat = 'identity')
head(mpg)
head(mpg_counted)
vlibrary(dplyr)
mpg_counted <- mpg %>%
count(class, name = 'count')
ggplot(mpg_counted) +
geom_bar(aes(x = class, y = count), stat = 'identity'
library(dplyr)
mpg_counted <- mpg %>%
count(class, name = 'count')
ggplot(mpg_counted) +
geom_bar(aes(x = class, y = count), stat = 'identity'))
library(dplyr)
mpg_counted <- mpg %>%
count(class, name = 'count')
ggplot(mpg_counted) +
geom_bar(aes(x = class, y = count), stat = 'identity')
ggplot(mpg_counted) +
geom_col(aes(x = class, y = count))
ggplot(mpg_counted) +
geom_col(aes(x = class, y = count))
ggplot(mpg) +
geom_bar(aes(x = class, y = after_stat(100 * count / sum(count))))
ggplot(mpg) +
geom_density(aes(x = hwy))
ggplot(mpg) +
geom_density(aes(x = hwy, y = after_stat(scaled)))
x <- runif(0,1)
range(x)
x
x <- runif(100,0,1)
range(x)
y <- runif(100,0,1)
cor(x,y)
plot(x,y)
nsnps = 100
annot_c = rnorm(100)
ld = matrix(rnorm(1000, 0.4, 0.0001), nrow = 100)
max(ld)
min(ld)
ld = matrix(rnorm(1000, 0.4, 0.01), nrow = 100)
max(ld)
min(ld)
ld = matrix(rnorm(1000, 0.4, 0.1), nrow = 100)
max(ld)
min(ld)
dim(ld)
ld = matrix(rnorm(10000, 0.4, 0.1), nrow = 100)
max(ld)
dim(ld)
annot_c * ld
dim(annot_c * ld)
dim(annot_c %*% ld)
annot_c %*% ld
l = annot_c %*% ld
l
sum(annot_c * ld)
sum(annot_c * ld[1,])
sum(annot_c * ld[,1])
chisq = rnorm(nsnps, 3, 1)
range(chisq)
annot_c = rnorm(nsnps)
ld = matrix(rnorm(nsnps*nsnps, 0.4, 0.1), nrow = 100)
max(ld)
dim(ld)
ld %*% annot_c
l = ld %*% annot_c
sum(annot_c * ld[1,])
lm(chisq ~ l)
summary(lm(chisq ~ l))
weight <- sample(c(0.5,0.6,0.7,0.8,0.9),1)
weight
weight <- sample(c(0.5,0.6,0.7,0.8,0.9),1)
weight
rm(list=ls())
rm(list=ls())
setwd("~/Google Drive/PhD/R_packages/fcfdr")
