}
output <- list(res, 1)
ouput
str(output)
output <- list(data.frame(p = res$p, v = res$v1, q = res$q1), 1)
output <- list(res, 1)
output <- list(data.frame(p = res$p, v = res$v1, q = res$q1), 1)
str(output)
log10pv_plot(output)
min(-log10(output[[1]]$p)
)
getwd()
setwd("~/Google Drive/PhD/cFDR_appnote")
x <- readRDS("T1D_application_data.RDS")
df <- x
df
save(df, "T1D.RData")
save(df, file = "T1D.RData")
=======
load_all()
library(devtool)
library(devtools)
load_all()
load_all()
check()
check()
use_mit_license()
use_mit_license(Anna Hutcinson)
check()
check()
check()
check()
check()
usethis::use_vignette("fcfdr-vignette")
load(fcfdr)
load_all()
document()
build_vignettes()
load_all()
build_vignettes()
.Last.error.trace
library(fcfdr)
set.seed(1)
n = 50000
n1p = 500 # associated variants
zp = c(rnorm(n1p, sd=5), rnorm(n-n1p, sd=1)) # z-scores
p = 2*pnorm(-abs(zp)) # convert to p-values
mixture_comp1 <- function(x) rnorm(x, mean = -0.5, sd = 0.5)
mixture_comp2 <- function(x) rnorm(x, mean = 2, sd = 1)
n = length(p)
z = runif(n)
q <- c(mixture_comp1(n1p), mixture_comp2(n-n1p))
hist(q)
corr_plot(p, q)
res <- flexible_cfdr(p, q, indep_index = seq(1, n, 1), rmseg = TRUE)
build_vignettes()
document()
library(fcfdr)
build_vignettes()
check()
library(devtools)
build_readme()
use_readme_rmd(open = rlang::is_interactive())
pkgdown::build_site()
devtools::document()
pkgdown::build_site()
devtools::document()
devtools::check()
devtools::check()
devtools::document()
devtools::load_all()
devtools::check()
>>>>>>> 9f4d11885d8c88bf477fe8dd9ee1195da98da514
devtools::document()
devtools::load_all()
devtools::build()
pkgdown::build_articles()
pkgdown::build_articles()
pkgdown::build_articles()
pkgdown::build_articles()
pkgdown::build_site()
devtools::document()
pkgdown::build_site()
devtools::document()
devtools::document()
set.seed(1)
library(fcfdr)
n = 50000
n1p = 500 # associated variants
zp = c(rnorm(n1p, sd=5), rnorm(n-n1p, sd=1)) # z-scores
p = 2*pnorm(-abs(zp)) # convert to p-values
hist(p)
mixture_comp1 <- function(x) rnorm(x, mean = -0.5, sd = 0.5)
mixture_comp2 <- function(x) rnorm(x, mean = 2, sd = 1)
n = length(p)
z = runif(n)
q <- c(mixture_comp1(n1p), mixture_comp2(n-n1p))
hist(q)
corr_plot(p, q)
res <- flexible_cfdr(p, q, indep_index = seq(1, n, 1))
str(res)
p = res[[1]]$p
q = res[[1]]$q
v = res[[1]]$v
pv_plot(p, q, v)
log10pv_plot(p, q, v,
axis_lim = c(0, 10)) # zoom in to interesting region
hit = which(p.adjust(v, method = "BH") <= 0.05)
hit_p = which(p.adjust(p, method = "BH") <= 0.05)
hit
1- (length(intersect(hit,c(1:500)))/length(hit))
1- (length(intersect(hit_p,c(1:500)))/length(hit_p))
hit_p
which(hit <= 500)
which(hit !%in% hit_p)
which(!hit %in% hit_p)
hit
hit_p
which(!hit %in% hit_p)
intersect(hit,c(1:500)
)
!hit %in% hit_p
hit[!hit %in% hit_p]
pv_plot(p = p, q = q, v = v)
devtools::load_all()
rm(list = c("n"))
devtools::load_all()
devtools::check()
pkgdown::build_site()
pkgdown::build_site()
setwd("~/Google Drive/PhD/Supervisor meetings/functional_genomics/application/18nov")
new_robertson_gwas <- readRDS("robertson2020_hg19.RDS")
head(new_ro)
head(new_robertson_gwas)
snp_data <- new_robertson_gwas[,c("ID","hg19_pos","chromosome","pphaseIandIII")]
snp_data <- new_robertson_gwas[,c("ID","hg19_pos","chromosome","pphaseIandII")]
colnames(snp_data) <- c("SNP","BP","CHR","P")
head(snp_data)
for(i in 1:22){
write.table(snp_data[which(snp_data$CHR==i),], file = paste0("loci/chr",i,".assoc"), quote = FALSE, row.names=FALSE)
}
ldak_weights <- read.table("loci/results.clumping.txt")
str(ldak_weights)
res <- readRDS("res_calderon_matching.RDS")
str(res)
p <- res[[1]]$pphaseIandII
not <- which(is.na(res[[1]]$logFC))
not
res[[1]]$group <- cut(res[[1]][-not, "logFC"], breaks = quantile(res[[1]][-not, "logFC"]))
res[[1]][-not, "logFC"]
res[[1]]$group <- cut(c(res[[1]][-not, "logFC"]), breaks = quantile(res[[1]][-not, "logFC"]))
res[[1]]$group <- cut(c(res[[1]][-not, "logFC"]), breaks = quantile(c(res[[1]][-not, "logFC"])))
res[[1]]$logFC[-not]
res[[1]]$group <- cut(res[[1]]$logFC[-not], breaks = quantile(res[[1]]$logFC[-not]))
not <- which(is.na(res[[1]]$logFC))
res[[1]]$group[-not] <- cut(res[[1]]$logFC[-not], breaks = quantile(res[[1]]$logFC[-not]))
head(res[[1]])
p[not]
m <- melt(res[[1]][,c("pphaseIanII","group")])
m <- melt(res[[1]][,c("pphaseIandII","group")])
m
m <- melt(res[[1]][,c("pphaseIandII","group")], "group")
m
unique(m$group)
quantile(res[[1]]$logFC[-not])
not <- which(is.na(res[[1]]$logFC))
res[[1]]$group[-not] <- cut(res[[1]]$logFC[-not], breaks = quantile(res[[1]]$logFC[-not]))
res[[1]]$group[-not]
m <- melt(res[[1]][,c("pphaseIandII","group")], "group")
unique(m$group)
qqplot(p[not], p[which(m$group==levels(m$group[1]))])
qqplot(p[not], p[which(m$group==levels(m$group[2]))])
p[not]
p[which(m$group==levels(m$group[2]))]
qqplot(p[not], p[which(m$group==levels(m$group)[2])])
p[which(m$group==levels(m$group)[2])]
levels(m$group)[2]
unique(m$group)
qqplot(p[not], p[which(m$group==unique(m$group)[2])])
p <- res[[1]]$pphaseIandII
x <- res[[1]]
not <- which(is.na(x$logFC))
not
x$logFC[-not]
x$group[-not] <- cut(x$logFC[-not], breaks = quantile(x$logFC[-not]))
head(x)
quantile(x$logFC[-not])
unique(x$group)
table(x$group)
m <- melt(x[,c("pphaseIandII","group")], "group")
unique(m$group)
m
split(m, group)
split(m, m$group)
lapply(split(m, m$group), function(x) mean(x$value))
m <- melt(res[,c("V5","group","logFC")],"group")
head(res)
m <- melt(x[,c("pphaseIandII","group", "logFC")], "group")
head(m)
m <- melt(x[,c("logFC","group")], "group")
head(m)
lapply(split(m, m$group), function(x) mean(x$value))
m <- melt(x[,c("pphaseIandII","group")], "group")
unique(m$group)
qqplot(p[not], p[which(m$group==1)])
qqplot(p[not], p[which(m$group==1)], pch = 16)
points(p[not], p[which(m$group==2)], pch = 16, col = "red")
points(qqplot(p[not], p[which(m$group==2)],plot.it = F), pch = 16, col = "red")
points(qqplot(p[not], p[which(m$group==3)],plot.it = F), pch = 16, col = "blue")
points(qqplot(p[not], p[which(m$group==4)],plot.it = F), pch = 16, col = "green")
qqplot(-log10(p[not]), -log10(p[which(m$group==1)]), ylab = "SNPs in peak (stratifed by logFC)", xlab = "SNPs not in peak", pch = 16, main = "Stratified QQ plot for (-log10) p-vals")
p[which(m$group==1)]
abline(0,1)
points(qqplot(-log10(p[not]), -log10(p[which(m$group==2)]),plot.it = F), pch = 16, col = "red")
points(qqplot(-log10(p[not]), -log10(p[which(m$group==3)]),plot.it = F), pch = 16, col = "blue")
points(qqplot(-log10(p[not]), -log10(p[which(m$group==4)]),plot.it = F), pch = 16, col = "green")
quantile(x$logFC[-not])
legend(200,150, legend = c(0.25, 0.5, 0.75, 1), col = c("black","red","blue","green"), pch = 16, title = "logFC quantile")
legend(150,3, legend = c(0.25, 0.5, 0.75, 1), col = c("black","red","blue","green"), pch = 16, title = "logFC quantile")
qs_logFC <- lapply(res, function(x){
x$logFC[is.na(x$logFC)] <- 0
x$logFC
})
p <- res[[1]]$pphaseIandII
q
qs_logFC
x <- res[[1]]
not <- which(is.na(x$logFC))
qqplot(p[not], p[-not])
qqplot(-log10(p[not]), -log10(p[which(m$group==1)]), ylab = "SNPs in peak (stratifed by logFC)", xlab = "SNPs not in peak", pch = 16, main = "Stratified QQ plot for (-log10) p-vals")
headd(m)
head(m)
qqplot(-log10(p[not]), -log10(m$value[which(m$group==1)]), ylab = "SNPs in peak (stratifed by logFC)", xlab = "SNPs not in peak", pch = 16, main = "Stratified QQ plot for (-log10) p-vals")
abline(0,1)
qqplot(-log10(p[not]), -log10(m$value[which(m$group==1)]), ylab = "SNPs in peak (stratifed by logFC)", xlab = "SNPs not in peak", pch = 16, main = "Stratified QQ plot for (-log10) p-vals")
abline(0,1)
points(qqplot(-log10(p[not]), -log10(m$value[which(m$group==2)]),plot.it = F), pch = 16, col = "red")
points(qqplot(-log10(p[not]), -log10(m$value[which(m$group==3)]),plot.it = F), pch = 16, col = "blue")
points(qqplot(-log10(p[not]), -log10(m$value[which(m$group==4)]),plot.it = F), pch = 16, col = "green")
qqplot(-log10(p[not]), -log10(p[-not]), ylab = "SNPs in peak", xlab = "SNPs not in peak", pch = 16, main = "QQ plot for (-log10) p-vals")
abline(0,1)
str(qs_logFC)
# how many are non-zero
lapply(qs_logFC, function(x) length(which(x!=0)))
4/16
5/16
7/16
2/23
21/23
getwd
pkgdown::build_site()
devtools::document()
devtools::load_all()
devtools::check()
library(devtools)
devtools::document()
devtools::load_all()
devtools::load_all()
devtools::document()
devtools::document()
devtools::load_all()
devtools::check()
devtools::check()
devtools::build()
devtools::document()
pkgdown::build_site()
install.packages(c('Rcpp', 'rstan'), dependencies = TRUE, type = 'source')
install.packages(c("Rcpp", "rstan"), dependencies = TRUE, type = "source")
devtools::install_github("andrewGhazi/malacoda", build_vignettes = TRUE)
library (malacoda)
qqnorm
qqnorm)_
qqnorm()
set.seed(1)
n = 50000
n1p = 500 # associated variants
zp = c(rnorm(n1p, sd=5), rnorm(n-n1p, sd=1)) # z-scores
p = 2*pnorm(-abs(zp)) # convert to p-values
hist(p)
mixture_comp1 <- function(x) rnorm(x, mean = -0.5, sd = 0.5)
mixture_comp2 <- function(x) rnorm(x, mean = 2, sd = 1)
n = length(p)
z = runif(n)
q <- c(mixture_comp1(n1p), mixture_comp2(n-n1p))
hist(q)
indep_index = seq(1, n, 1)
nxbin = 1000; res_p = 300; res_q = 500; gridp = 50; splinecorr = TRUE; dist_thr = 0.5; plot_KDE = FALSE
plot_KDE = TRUE
if( sign(cor(p[indep_index], q[indep_index], method="spearman"))!= sign(cor(p, q, method="spearman")) ) stop('Correlation between p and q in whole dataset has a different sign to that in independent subset of SNPs')
# ensure low q enriched for low p
if(cor(p[indep_index], q[indep_index], method="spearman") < 0) q <- -q
zp = -qnorm(p/2) # convert p-vals to z-scores
# define support for KDE (range of data +/- 10%)
q_10 <- (max(q) - min(q)) * 0.1
zp_10 <- (max(zp) - min(zp)) * 0.1
lims <- c(0, max(zp) + zp_10, min(q) - q_10, max(q) + q_10) # c(xl, xu, yl, yu)
# folded normal KDE only computed for independent SNPs (so BW computation isnt biased)
p_ind <- p[indep_index]
zp_ind <- zp[indep_index]
q_ind <- q[indep_index]
# bivariate density of zp and q
kpq <- MASS::kde2d(c(zp_ind, -zp_ind), c(q_ind, q_ind), n = c(res_p, res_q), lims = lims)
# find optimal mlests parameter values
N = length(c(zp_ind, -zp_ind)); b = 4.3 * exp(-0.26 * log(N, 10)); med = median(c(zp_ind, -zp_ind))
sc = diff(quantile(c(zp_ind, -zp_ind))[c(2,4)])/(2*qnorm(.75))
mlests = locfdr:::locmle(c(zp_ind, -zp_ind), xlim=c(med, b*sc))
names(mlests) = NULL
# local FDR = P(H0|ZP=zp)
lfdr <- locfdr(c(zp_ind, -zp_ind), bre = c(kpq$x[-length(kpq$x)] + diff(kpq$x)/2, kpq$x[length(kpq$x)] + diff(kpq$x)[length(diff(kpq$x))]/2, -c(kpq$x[-length(kpq$x)] + diff(kpq$x)/2, kpq$x[length(kpq$x)] + diff(kpq$x)[length(diff(kpq$x))]/2)), mlests = c(mlests[1], b*mlests[2]), plot = 0, df = 10)
# extract lfdr values for kpq$x values
lfdr_vals <- lfdr$mat[res_p:length(lfdr$mat[,1]),][,2]
library(locfdr)
# local FDR = P(H0|ZP=zp)
lfdr <- locfdr(c(zp_ind, -zp_ind), bre = c(kpq$x[-length(kpq$x)] + diff(kpq$x)/2, kpq$x[length(kpq$x)] + diff(kpq$x)[length(diff(kpq$x))]/2, -c(kpq$x[-length(kpq$x)] + diff(kpq$x)/2, kpq$x[length(kpq$x)] + diff(kpq$x)[length(diff(kpq$x))]/2)), mlests = c(mlests[1], b*mlests[2]), plot = 0, df = 10)
# extract lfdr values for kpq$x values
lfdr_vals <- lfdr$mat[res_p:length(lfdr$mat[,1]),][,2]
lfdrmat <- matrix(lfdr_vals,nrow(kpq$z),ncol(kpq$z))
Pr.pqh0 <- lfdrmat * kpq$z # prob(p,q,H0)
Pr.q.h0 <-  colSums(Pr.pqh0)/sum(Pr.pqh0) # prob(q|H0) = prob(q,H0)/prob(H0)
Pr.cq.h0 <- cumsum(Pr.q.h0) # prob (Q<q | H0)
int_kqh0 <- t(outer(Pr.cq.h0, rep(1, res_p)))
int_kqh0 <- int_kqh0/max(int_kqh0)
plot(kpq$y,Pr.q.h0)
density(q)
plot(density(q))
points(density(q), col = "red")
lines(density(q), col = "red")
plot(density(q))
lines(density(q), col = "red")
dim(kpq$z)
plot(c(q_ind, q_ind), kpq$z[,res_q])
plot(kpq$y, kpq$z[,res_q])
plot(kpq$y, kpq$z[,res_p])
length(kpq$y)
plot(kpq$y, kpq$z[res_p,])
plot(kpq$y, kpq$z[res_q,])
plot(kpq$y, kpq$z[1,])
plot(kpq$y, kpq$z[1,])
lines(density(q[ind])
)
lines(density(q_ind))
?density
density(q_ind)
plot(density(q_ind))
plot(kpq$y, kpq$z[1,]/max(kpq$z[1,]))
lines(density(q_ind))
plot(kpq$y, int_kpq[1,], )
cell_size <- (diff(range(lims[1], lims[2])) / res_p) * (diff(range(lims[3], lims[4])) / res_q)
integ <- sum(kpq$z) * cell_size
kpq_norm <- kpq$z/integ
int_kpq <- t(apply(apply(kpq_norm[res_p:1,], 2, cumsum), 1, cumsum))[res_p:1, ]
int_kpq <- int_kpq/max(int_kpq)
# kgrid estimates P(P<=p, Q<=q)/P(Q<=q|H0)
kgrid <- kpq
kgrid$z <- exp(log(int_kpq)-log(int_kqh0))
# avoid 0-0 errors
kgrid$z[which(kgrid$z==0)] <- min(kgrid$z[which(kgrid$z>0)])
plot(kpq$y, int_kpq[1,])
integ
plot(kpq$y, int_kpq[,1])
plot(kpq$y, kpq_norm[1,])
plot(kpq$y, kpq_norm[1,])
lines(density(q_ind), col = "red")
plot(kpq$y, kpq_norm[1,]/max(kpq_norm[1,]))
lines(density(q_ind)/max(density(q_ind)), col = "red")
hist(q_ind)
lines(kpq$y, kpq_norm[1,])
hist(q_ind, freq = FALSE)
lines(kpq$y, kpq_norm[1,])
hist(q_ind, freq = FALSE, xlab = "q", main = "Histogram of q with\nestimated density in red")
lines(kpq$y, kpq_norm[1,], col =  "red")
#' @import fields
#' @import stats
#' @import polyCub
#' @import hexbin
#' @import bigsplines
#' @import grDevices
#'
#'
#' @return list of length two: (1) dataframe of p-values, q-values and v-values (2) dataframe of auxiliary data (q_low used for left censoring, how many data-points were left censored and/or spline corrected)
#' @export
flexible_cfdr <- function(p, q, indep_index, nxbin = 1000, res_p = 300, res_q = 500, gridp = 50, splinecorr = TRUE, dist_thr = 0.5, plot_KDE = FALSE){
if( sign(cor(p[indep_index], q[indep_index], method="spearman"))!= sign(cor(p, q, method="spearman")) ) stop('Correlation between p and q in whole dataset has a different sign to that in independent subset of SNPs')
# ensure low q enriched for low p
if(cor(p[indep_index], q[indep_index], method="spearman") < 0) q <- -q
zp = -qnorm(p/2) # convert p-vals to z-scores
# define support for KDE (range of data +/- 10%)
q_10 <- (max(q) - min(q)) * 0.1
zp_10 <- (max(zp) - min(zp)) * 0.1
lims <- c(0, max(zp) + zp_10, min(q) - q_10, max(q) + q_10) # c(xl, xu, yl, yu)
# folded normal KDE only computed for independent SNPs (so BW computation isnt biased)
p_ind <- p[indep_index]
zp_ind <- zp[indep_index]
q_ind <- q[indep_index]
# bivariate density of zp and q
kpq <- MASS::kde2d(c(zp_ind, -zp_ind), c(q_ind, q_ind), n = c(res_p, res_q), lims = lims)
### estimate P(Q<=q|H0)
# find optimal mlests parameter values
N = length(c(zp_ind, -zp_ind)); b = 4.3 * exp(-0.26 * log(N, 10)); med = median(c(zp_ind, -zp_ind))
sc = diff(quantile(c(zp_ind, -zp_ind))[c(2,4)])/(2*qnorm(.75))
mlests = locfdr:::locmle(c(zp_ind, -zp_ind), xlim=c(med, b*sc))
names(mlests) = NULL
# local FDR = P(H0|ZP=zp)
lfdr <- locfdr(c(zp_ind, -zp_ind), bre = c(kpq$x[-length(kpq$x)] + diff(kpq$x)/2, kpq$x[length(kpq$x)] + diff(kpq$x)[length(diff(kpq$x))]/2, -c(kpq$x[-length(kpq$x)] + diff(kpq$x)/2, kpq$x[length(kpq$x)] + diff(kpq$x)[length(diff(kpq$x))]/2)), mlests = c(mlests[1], b*mlests[2]), plot = 0, df = 10)
# extract lfdr values for kpq$x values
lfdr_vals <- lfdr$mat[res_p:length(lfdr$mat[,1]),][,2]
lfdrmat <- matrix(lfdr_vals,nrow(kpq$z),ncol(kpq$z))
Pr.pqh0 <- lfdrmat * kpq$z # prob(p,q,H0)
Pr.q.h0 <-  colSums(Pr.pqh0)/sum(Pr.pqh0) # prob(q|H0) = prob(q,H0)/prob(H0)
Pr.cq.h0 <- cumsum(Pr.q.h0) # prob (Q<q | H0)
int_kqh0 <- t(outer(Pr.cq.h0, rep(1, res_p)))
int_kqh0 <- int_kqh0/max(int_kqh0)
### estimate P(P<=p, Q<=q)
cell_size <- (diff(range(lims[1], lims[2])) / res_p) * (diff(range(lims[3], lims[4])) / res_q)
integ <- sum(kpq$z) * cell_size
kpq_norm <- kpq$z/integ
int_kpq <- t(apply(apply(kpq_norm[res_p:1,], 2, cumsum), 1, cumsum))[res_p:1, ]
int_kpq <- int_kpq/max(int_kpq)
# kgrid estimates P(P<=p, Q<=q)/P(Q<=q|H0)
kgrid <- kpq
kgrid$z <- exp(log(int_kpq)-log(int_kqh0))
# avoid 0-0 errors
kgrid$z[which(kgrid$z==0)] <- min(kgrid$z[which(kgrid$z>0)])
if(plot_KDE == TRUE){
hist(q_ind, freq = FALSE, xlab = "q", main = "Histogram of q with\nestimated density in red")
lines(kpq$y, kpq_norm[1,], col =  "red")
}
# cgrid is grid of cFDR values
# estimated by p/kgrid
cgrid <- vector(mode = "list", length = 3)
cgrid$x = c(seq(0, 0.05, length.out = 101)[1:100], seq(0.05, lims[2], length.out = res_p))
cgrid$y = seq(lims[3], lims[4], length.out = res_q)
ptest = 2*pnorm(-cgrid$x)
cfdrs <- matrix(rep(0, length(cgrid$y)*length(cgrid$x)), ncol = length(cgrid$y))
for (i in 1:length(cgrid$y)) {
xdenom=interp.surface(kgrid,cbind(cgrid$x, rep(cgrid$y[i], length(cgrid$x))))
cfdrs[,i]=cummin(ptest/xdenom)
}
cgrid$z <- cfdrs
# left-censoring
q_grid <- seq(lims[3], lims[4], length.out = res_q)
groups <- cut(q_ind, breaks = q_grid, include.lowest = TRUE, right = TRUE)
# use left point of region where the number of points used for estimation in that bin is >gridp
q_low <- q_grid[which(table(groups)>gridp)[1]]
q_cens <- q
q_cens[which(q_cens < q_low)] <- q_low
# bivariate binning
binned_res <- hexbin(zp, q_cens, xbins = nxbin, IDs = TRUE)
bins <- cbind(binned_res@xcm, binned_res@ycm)
ccut <- interp.surface(cgrid, bins) # cFDR values for binned data
# L-curves are contours of cFDR curves
cl <- lapply(ccut, function(l) grDevices::contourLines(x=cgrid, levels=l))
cl_basic <- cl
# rearrage L-curves so they are defined anticlockwise
lengths <- lapply(cl, length)
for(i in which(lengths>1)){
first = lapply(cl[[i]], function(x) x$y[1]) %>% unlist()
cl[[i]] = cl[[i]][order(first)]
}
# remove contour coords in problematic low q regions
for(i in which(lengths>1)){
cl[[i]][[1]] <- NULL
}
# define newx and newy as joined segments
for(i in 1:length(cl)){
cl[[i]]$newx <- c()
for(j in 1:length(cl[[i]])){
cl[[i]]$newx <- c(cl[[i]]$newx, cl[[i]][[j]]$x)
cl[[i]]$newy <- c(cl[[i]]$newy, cl[[i]][[j]]$y)
}
}
Lx <- lapply(cl, function(x) 2*pnorm(-abs(x$newx)))
Ly <- lapply(cl, function(x) x$newy)
### estimate P(P=p,Q=q|H0)=P(P=q|H0)*P(Q=q|H0)
fph0 = function(x) dunif(x) # P|H0
fqh0 <- approxfun(kpq$y, Pr.q.h0) # Q|H0
fpqh0 <- function(s){
fph0(s[,1])*fqh0(s[,2])
}
# normalise so integral is 1 over full region
fullint <- polyCub(owin(poly=list(x = c(1, 0, 0, 1), y = c(lims[4], lims[4], lims[3], lims[3])), check = FALSE, fix = FALSE), fpqh0, method = "midpoint")
fpqh0 <- function(s){
fph0(s[,1])*fqh0(s[,2])/fullint
}
# integrate bivariate null over L region to get v-vals
v_tmp <- mapply(function(X, Y){
polyCub(owin(poly=list(x = c(X[length(X)], 0,0, c(X[1],X)), y = c(lims[4], lims[4], lims[3], c(lims[3],Y))), check = FALSE, fix  = FALSE), fpqh0, method = "midpoint")
}, X = Lx, Y = Ly)
# map back binned data to original data points
v <- v_tmp[match(binned_res@cID, binned_res@cell)]
v_b4spline <- v
v[which(v==0)] <- 1e-100 # replace any 0 v-vals
if(splinecorr == TRUE){ # spline correction
spline_fit <- bigspline(x = q, y = log10(v/p), nknots = 5, rparm = NA)
#pred_out <- predict.bigspline(spline_fit, newdata = seq(min(q), max(q), 0.05))
distances <- abs(log10(v/p)-spline_fit$fitted.values)
corrected_ind <- which(abs(log10(v/p)-spline_fit$fitted.values) > dist_thr)
v[corrected_ind] <- pmin(10^spline_fit$fitted[corrected_ind]*p[corrected_ind], 1)
}
v[which(v>1)] <- 1 # fix bug where some v vals = 1 + 2.220446e-16
df <- data.frame(p, q, v)
return(list(df, data.frame(q_low = q_low, left_cens = length(which(q < q_low)), splinecorr = length(corrected_ind))))
}
res <- flexible_cfdr(p, q, indep_index = seq(1, n, 1), plot_KDE = T)
library(fcfdr)
plot(1)
res <- flexible_cfdr(p, q, indep_index = seq(1, n, 1), plot_KDE = TRUE)
res <- flexible_cfdr(p, q, indep_index = seq(1, n, 1), plot_KDE = FALSE)
devtools::document()
rm(list = c("flexible_cfdr", "lims", "n"))
devtools::document()
devtools::check()
